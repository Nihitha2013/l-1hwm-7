import google.generativeai as g

g.configure(api_key="AIzaSyDkpC5PHSEmqGW_FONRjJa8F0hNiwY44c0")


def generate_response(prompt):
    model=g.GenerativeModel(model_name="gemini-2.5-flash")
    response=model.generate_content(prompt)
    return response.text

def prompt_engineering_activity():
    print("Welcome to the AI prompt Engineering Tutorial!")

    vague_prompt=input("Enter a vague prompt:")
    print("\nAI's response to vague prompt:")
    print(generate_response(vague_prompt))

    specific_prompt=input("\nNow, make it more specific: ")
    print("\nAI's response to specific prompt:")
    print(generate_response(specific_prompt))

    contextual_prompt=input("\nNow, add context to your specific prompt:")
    print("\nAI's response to contextual prompt:")
    print(generate_response(contextual_prompt))

    print("\n--- Reflection ---")
    print("1. How did the AI's response change when the prompt was made more specific?")
    print("2. How did the AI's response improve with the added context?")
    print("3.Which prompt produced the most relevant and tailored response? Why?")

    